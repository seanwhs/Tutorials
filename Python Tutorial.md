# üêç **The Practical Python Mastery Guide**

## **Learn Python by Building a Complete, Real Application ‚Äî Then Scale It Like a Pro**

**Edition:** 1.1
**Audience:** Beginners ‚Üí Junior Engineers ‚Üí Bootcamp Learners ‚Üí Early Professionals
**Learning Style:** Build-first, explain-when-needed
**Primary Outcome:** Transition from writing "scripts" to engineering maintainable, scalable "systems"

---

## üåü The Application We Will Build

We will build **PyInsight**, a production-ready Python CLI application for data analysis.

**Features:**

* Ingress Layer: CLI interface handling user arguments and commands
* Processing Layer: CSV loading, validation, and analytics
* Core Engine: Functional and OOP-based analysis
* Egress Layer: Structured logs, reports in terminal and file formats (JSON/CSV)
* Extensible CLI commands for automation
* Fully testable, packageable, and deployable
* Can handle large datasets and multi-user scenarios

---
PyInsight is a **production-grade CSV analysis and rule-based pipeline tool**. Its architecture makes it suitable for **data-heavy, operational, or analytics workflows**, especially where **automation, async processing, and plugin extensibility** are needed. Here‚Äôs a practical breakdown:

---

## 1Ô∏è‚É£ **Data Analysis & Reporting**

* **Quick CSV analytics:** Summarize, validate, and report on CSV datasets.
* **Automated reporting pipelines:** Generate terminal reports, JSON, CSV, or Excel outputs for dashboards.
* **Examples:**

  * Sales CSV ‚Üí average sales, min/max, flagged anomalies.
  * Sensor data ‚Üí daily metrics summary.

---

## 2Ô∏è‚É£ **Rule-Based Monitoring**

* **Custom rules engine:** Evaluate datasets against declarative rules (`rules.yaml`).
* **Alerts & flags:** Automatically detect thresholds, anomalies, or policy violations.
* **Examples:**

  * Finance: Flag transactions above a threshold.
  * HR: Identify employees with missing critical data.
  * IoT: Trigger warnings for out-of-range sensor readings.

---

## 3Ô∏è‚É£ **Plugin-Driven Extensibility**

* **Custom analytics plugins:** Users can write domain-specific analysis modules.
* **Parallel execution:** Plugins run asynchronously to extend core capabilities without blocking pipelines.
* **Examples:**

  * Technical indicators in stock data (RSI, volatility).
  * Data enrichment from APIs (geolocation, weather, currency rates).
  * Machine learning inference pipelines.

---

## 4Ô∏è‚É£ **Asynchronous Processing & Streaming**

* **Large dataset handling:** Async CSV loading and async computations reduce blocking for big files.
* **Streaming / API integrations:** Can adapt to streaming data from web APIs or IoT feeds.
* **Examples:**

  * Processing millions of rows in batches without blocking.
  * Live analytics of telemetry or financial feeds.

---

## 5Ô∏è‚É£ **Observability & Metrics**

* Integrated **OpenTelemetry metrics, logs, and traces**.
* **Operational monitoring:** Track rows processed, plugin execution times, and rule evaluations.
* **Example:** Monitor pipeline health and performance in production dashboards.

---

## 6Ô∏è‚É£ **Secure & Configurable**

* Secrets management via environment variables or Vault/KMS.
* Flexible configuration (`pyinsight.toml`) for data source paths, report formats, and analysis defaults.
* Ensures pipelines **don‚Äôt leak credentials** and can adapt to different environments.

---

## 7Ô∏è‚É£ **Deployment & Automation**

* **Dockerized:** Ready for containerized deployment.
* **Kubernetes-friendly:** Can run batch jobs, cron jobs, or scheduled analytics.
* **CI/CD pipelines:** Easy to integrate into existing DevOps workflows.
* **Example:** Nightly batch analytics on operational CSV datasets.

---

### ‚úÖ **Real-World Use Cases**

1. **Finance / Trading Analytics:** Automatically compute indicators, flag high/low values, generate reports for traders.
2. **Operations & Logistics:** Daily validation and summary of shipment or inventory CSVs.
3. **IoT & Sensor Data:** Async ingestion and summarization, detect anomalies, plug in ML models.
4. **HR & Compliance:** Validate employee records, detect missing or abnormal values, flag compliance issues.
5. **Data Engineering / Pipelines:** Build modular ETL steps that can integrate plugins, rules, and metrics into production pipelines.

---

In short, **PyInsight is like a modular, production-grade ‚ÄúCSV + Rule + Plugin‚Äù automation engine**, designed for **analytics, validation, monitoring, and reporting workflows** in real-world business or operational settings.

---

# üó∫Ô∏è PyInsight ‚Äî Practical Applications Map

```
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ        PyInsight          ‚îÇ
                         ‚îÇ  CSV + Rules + Plugins    ‚îÇ
                         ‚îÇ  Async, Metrics, Secure   ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚ñº                             ‚ñº                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Finance &     ‚îÇ             ‚îÇ Operations &   ‚îÇ             ‚îÇ IoT & Sensor  ‚îÇ
‚îÇ Trading       ‚îÇ             ‚îÇ Logistics      ‚îÇ             ‚îÇ Data          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - Compute RSI / Moving Avg    ‚îÇ - Validate shipments          ‚îÇ - Stream sensor data
‚îÇ - Flag high/low transactions ‚îÇ - Summarize inventory        ‚îÇ - Detect anomalies
‚îÇ - Auto reporting              ‚îÇ - Detect delays / issues     ‚îÇ - Async aggregation
‚îÇ - Plugin analytics (ML/AI)   ‚îÇ - Daily / batch reports      ‚îÇ - Plugin ML models
‚îÇ - Rule engine alerts          ‚îÇ - Rules: thresholds, flags  ‚îÇ - Alerts & notifications
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                             ‚îÇ                             ‚îÇ
       ‚ñº                             ‚ñº                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HR & Compliance‚îÇ             ‚îÇ Data Engineering‚îÇ           ‚îÇ DevOps &      ‚îÇ
‚îÇ & Payroll      ‚îÇ             ‚îÇ Pipelines       ‚îÇ           ‚îÇ Automation    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ - Validate employee records   ‚îÇ - ETL steps & CSV ingestion ‚îÇ - Batch jobs (K8s)
‚îÇ - Detect missing / abnormal   ‚îÇ - Async processing          ‚îÇ - Automated reports
‚îÇ   values                      ‚îÇ - Plugin enrichment (API,  ‚îÇ - Metrics / logs / alerts
‚îÇ - Compliance & policy checks  ‚îÇ   ML models)               ‚îÇ - Secrets / config injection
‚îÇ - Rule engine checks           ‚îÇ - Rule-based validations   ‚îÇ - Cron / scheduled pipelines
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ
                                     ‚ñº
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ Unified Output Layer  ‚îÇ
                           ‚îÇ - Terminal Reports    ‚îÇ
                           ‚îÇ - JSON / CSV / Excel  ‚îÇ
                           ‚îÇ - Alerts / Flags      ‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### üîë Map Explanation

1. **Central Engine:**
   PyInsight handles **CSV ingestion, validation, summarization, async processing, and plugin execution**.

2. **Industry Applications:**

   * **Finance/Trading:** Automated metrics, technical indicators, alerting.
   * **Operations & Logistics:** Daily batch reports, anomaly detection, shipment/inventory validation.
   * **IoT & Sensor Data:** Streaming data pipelines, async summarization, anomaly detection.
   * **HR & Compliance:** Employee data validation, missing data detection, policy compliance checks.
   * **Data Engineering Pipelines:** ETL automation, async enrichment, plugin-driven data processing.
   * **DevOps & Automation:** Containerized jobs, metrics collection, secrets injection, scheduled pipelines.

3. **Unified Output:**
   All pipelines merge results into a **consistent output**, including terminal summaries, JSON/CSV files, alerts, and flags.

---

**Text-Based Application Flow Diagram:**

```
User Input (CLI)
      ‚Üì
  CSV Loader
      ‚Üì
  Validator
      ‚Üì
  Analysis Engine
      ‚Üì
  Report Generator
      ‚Üì
Output (Terminal / File / JSON)
```

> Building this **real application** ensures every concept‚Äîfrom variables to CI/CD pipelines‚Äîhas a practical context.

---

## üåü Learning Outcomes

By the end of this guide, readers will be able to:

‚úî Read, write, and reason about Python code confidently
‚úî Apply functional and OOP paradigms
‚úî Build, test, and deploy a complete Python application
‚úî Implement error handling, logging, and observability
‚úî Use CLI frameworks like `argparse` and `typer`
‚úî Package Python projects into executable applications
‚úî Implement CI/CD pipelines for Python
‚úî Build scalable, maintainable systems

---

# üß† Core Learning Philosophy

> You don‚Äôt learn Python by memorizing syntax. You learn by **solving real problems under constraints repeatedly**.

**Guiding Principle:**

```
"Memorized syntax is a liability; understood patterns are an asset."
```

We introduce concepts **only when PyInsight needs them**:

* Code breaks ‚Üí Learn Error Handling
* Code gets messy ‚Üí Learn Functional Programming
* Code needs state ‚Üí Learn OOP
* Code must ship ‚Üí Learn Packaging & CI/CD

> This mirrors **real-world Python engineering practices**.

---

# üß© Canonical Application Mental Model

```
User Input
   ‚Üì
Data Loading
   ‚Üì
Validation
   ‚Üì
Analysis Engine
   ‚Üì
Report Generation
   ‚Üì
Output (Terminal / File / CLI)
```

**Key Mindset:**

* Beginners: ‚ÄúMake it work‚Äù
* Professionals: ‚ÄúMake it safe, testable, and extensible‚Äù

---

# üß± PHASE 1 ‚Äî Python Foundations (Execution With Intent)

Python is more than syntax; it‚Äôs about **how the interpreter runs your code, stores data, and allows modular, maintainable designs**. This foundation sets the stage for PyInsight.

---

## 1Ô∏è‚É£ Program Entry & Execution Model

Python executes **top-to-bottom**, interpreting statements as it encounters them. Understanding **entry points** ensures modularity, prevents accidental execution, and supports testing.

```python
def main():
    print("Welcome to PyInsight!")

if __name__ == "__main__":
    main()
```

### Step-by-Step

1. **Define main logic in `main()`** ‚Äì isolates program functionality.
2. **Check `__name__ == "__main__"`** ‚Äì ensures code only runs when executed directly.
3. **Importing this module elsewhere** does not trigger `main()`; useful for unit tests.

### Execution Flow Diagram

```
Python Interpreter
     ‚îÇ
     ‚îú‚îÄ> Executes top-level statements
     ‚îú‚îÄ> Defines functions and classes
     ‚îî‚îÄ> __name__ check triggers main()
```

**Key Takeaways**

* Prevents code from executing on import
* Promotes modular design
* Facilitates automated testing

---

## 2Ô∏è‚É£ Variables, Data Types & Memory

Python variables **store references** to objects. Types are either **mutable** (can change in-place) or **immutable** (cannot change).

```python
# Immutable types
x = 10
name = "Alice"
pi = 3.1415
status = True
coordinates = (0, 0)

# Mutable types
numbers = [1, 2, 3]
person = {"name": "Alice", "score": 85}
flags = set(["ready", "valid"])
```

### Behavior Table

| Type      | Examples                          | Behavior                                              |
| --------- | --------------------------------- | ----------------------------------------------------- |
| Immutable | int, float, str, tuple, frozenset | Cannot modify in-place; operations create new objects |
| Mutable   | list, dict, set, bytearray        | Can modify in-place; shared references matter         |

### Memory Model Diagram

```
Immutable:
a = 10
b = a       # b points to same object 10
b = 20      # b now points to new object 20, a unchanged

Mutable:
numbers = [1,2,3]
numbers2 = numbers   # both variables point to same list
numbers.append(4)    # numbers2 sees [1,2,3,4]
```

**Practical Tip:** Understanding mutability prevents subtle bugs in PyInsight when passing lists/dicts across functions and classes.

---

## 3Ô∏è‚É£ Collections Module ‚Äî Advanced Python Data Structures

Python‚Äôs `collections` module offers **enhanced structures** for common patterns.

```python
from collections import deque, Counter, defaultdict, namedtuple

# Fast append/pop from both ends
queue = deque([1,2,3])
queue.appendleft(0)  # [0,1,2,3]

# Count occurrences
freq = Counter(["apple","banana","apple"])
# freq -> Counter({'apple': 2, 'banana': 1})

# Auto-initialize missing keys
d = defaultdict(list)
d["fruits"].append("apple")

# Immutable, tuple-like object
Point = namedtuple("Point", ["x","y"])
p = Point(1,2)
```

**Why Use Collections Module?**

* Guarantees predictable behavior
* Optimized for performance
* Reduces boilerplate code

---

## 4Ô∏è‚É£ Operators & Control Flow

Python offers **arithmetic, comparison, logical, membership, and identity operators**:

```
Arithmetic: + - * / // % **
Comparison: == != < > <= >=
Logical: and or not
Membership: in not in
Identity: is is not
```

### Control Flow & Truthiness

```python
if not filename:
    print("Filename required")
```

* Falsy values: `None`, `False`, `0`, `""`, `[]`, `{}`, `()`
* Everything else is **truthy**

**Step-by-Step:**

1. Evaluate the condition (`not filename`)
2. If `filename` is empty, execute block
3. Else, continue normal flow

---

## 5Ô∏è‚É£ Step-By-Step Mini Project Exercise

Readers can follow these steps to apply Phase 1 concepts:

1. **Create a Python file** `pyinsight_main.py`
2. **Define `main()`** with a simple print statement
3. **Use `__name__ == "__main__"`** check
4. **Declare a mix of mutable and immutable variables**
5. **Experiment with lists, dicts, sets, and collections module**
6. **Add control flow** checking for empty inputs
7. **Print results** and observe mutability effects

By completing this exercise, readers will **understand Python‚Äôs execution model, variables, mutability, collections, and control flow**, laying a strong foundation for building PyInsight.

---

# üß± PHASE 2 ‚Äî Data Structures in PyInsight

In PyInsight, CSV data is represented as a **list of dictionaries**, where each dictionary corresponds to a row. This structure allows the analysis engine to work with **flexible, mutable, and explicit data contracts**.

---

## 1Ô∏è‚É£ Core Data Structures

```python
# Single row as a dictionary
row = {"name": "Alice", "score": 85}

# Multiple rows as a list of dictionaries
rows = [row]

# Set for unique tags
tags = {"python", "data", "cli"}
```

### Key Points

* **Dicts** ‚Üí Key-value pairs, represent contracts for data
* **Lists** ‚Üí Ordered collections, mutable, used for rows
* **Sets** ‚Üí Unique items, fast membership checks, useful for tags or categories

---

## 2Ô∏è‚É£ Data Structure Flow Diagram

```
CSV Loader
    ‚îÇ
    ‚ñº
rows -> list of dicts (mutable)
tags -> set of unique categories (mutable)
summary -> dict of metrics (immutable once created)
```

*Rows flow through the system, tags represent unique categorical data, and summaries are immutable once calculated for safety.*

---

## 3Ô∏è‚É£ Working With Rows

Example: iterate and access data in rows

```python
for row in rows:
    print(f"{row['name']} scored {row['score']}")
```

*Output:*

```
Alice scored 85
```

*Note:* Modifying `rows` or `row` affects the underlying data because lists and dicts are **mutable**.

---

## 4Ô∏è‚É£ Adding and Removing Rows

```python
# Add a new row
rows.append({"name": "Bob", "score": 92})

# Remove a row
rows.pop(0)  # removes first row

# Update a value
rows[0]["score"] = 95
```

*Demonstrates mutability ‚Äî changes affect all references to the same object.*

---

## 5Ô∏è‚É£ CSV Loading ‚Äî Step-by-Step

PyInsight uses a simple loader function to read CSV files safely:

```python
import csv

def load_csv(path):
    """Load CSV file into a list of dictionaries."""
    with open(path, newline="") as f:  # context manager ensures file closes
        return list(csv.DictReader(f))
```

### Step-by-Step Notes

1. **Context Managers** (`with open(...) as f`)

   * Ensures files are **automatically closed**, even if an exception occurs.

2. **`csv.DictReader`**

   * Reads CSV rows into **dictionaries keyed by column names**.
   * Provides a **consistent contract** for downstream processing.

3. **Return as List**

   * Wraps rows in a **mutable list**, enabling easy iteration, filtering, and analysis.

---

## 6Ô∏è‚É£ Accessing CSV Data

```python
rows = load_csv("data.csv")

for row in rows:
    name = row["name"]
    score = int(row["score"])
    print(f"{name}: {score}")
```

*Ensures that CSV strings are converted to the correct data type (e.g., `int`, `float`).*

---

## 7Ô∏è‚É£ Optional: Collect Unique Categories

```python
tags = set(row["category"] for row in rows if "category" in row)
```

*Extracts all unique categories from a CSV column.*
*Sets are ideal because duplicates are automatically removed.*

---

## 8Ô∏è‚É£ Next Steps in PyInsight

After loading data, the **next phase** is **validation**:

* Ensure required columns exist
* Check for missing or malformed values
* Raise custom `DataError` exceptions for invalid rows

This keeps the pipeline **predictable and robust**.

---

> ‚úÖ **Takeaway:**
> Using **lists of dictionaries** and **sets** provides a flexible yet structured representation of CSV data. This approach forms the **backbone of PyInsight**, enabling analysis, reporting, and logging in later phases.

---

# üß± PHASE 3 ‚Äî Error Handling

Error handling is a **critical skill** for building robust Python applications. In PyInsight, we handle errors **gracefully**, giving clear messages, preventing crashes, and making debugging easier.

---

## 1Ô∏è‚É£ EAFP ‚Äî Easier to Ask for Forgiveness than Permission

Python encourages the **EAFP** style: assume operations will succeed and handle exceptions if they fail, instead of pre-checking everything.

```python
try:
    data = load_csv("data.csv")
except FileNotFoundError:
    print("File not found. Please check the file path.")
except PermissionError:
    print("Permission denied. Cannot read the file.")
```

**Why EAFP?**

* Less boilerplate code than checking every condition first
* Handles **unexpected edge cases** that pre-checks might miss
* Makes code **readable and Pythonic**

---

## 2Ô∏è‚É£ Using Multiple Exceptions

You can catch multiple types of errors in a single block:

```python
try:
    data = load_csv("data.csv")
except (FileNotFoundError, PermissionError) as e:
    print(f"Error loading CSV: {e}")
```

* `as e` captures the exception object for logging or debugging.*

---

## 3Ô∏è‚É£ Custom Exceptions

For **domain-specific errors**, define **custom exception classes**:

```python
class DataError(Exception):
    """Raised when dataset is invalid"""
```

**Example: Validate CSV Column**

```python
def validate_rows(rows):
    required_columns = ["name", "score"]
    for i, row in enumerate(rows, start=1):
        for col in required_columns:
            if col not in row:
                raise DataError(f"Row {i} missing required column '{col}'")
```

**Usage in PyInsight:**

```python
try:
    rows = load_csv("data.csv")
    validate_rows(rows)
except DataError as e:
    print(f"Validation failed: {e}")
```

*Benefits:*

* Improves **readability** and debugging
* Makes testing easier ‚Äî you can assert exceptions in unit tests
* Keeps **business logic** separate from general Python exceptions

---

## 4Ô∏è‚É£ Using `finally` and `else`

Python provides **`else`** and **`finally`** for more control:

```python
try:
    rows = load_csv("data.csv")
except FileNotFoundError:
    print("File not found")
else:
    print("CSV loaded successfully")
finally:
    print("Cleanup or closing resources")
```

* `else` runs if no exception occurred
* `finally` always runs, ideal for resource cleanup (closing files, DB connections)

---

## 5Ô∏è‚É£ Logging Exceptions

Instead of `print()`, log errors for production applications:

```python
import logging

logging.basicConfig(level=logging.INFO)
try:
    rows = load_csv("data.csv")
except FileNotFoundError as e:
    logging.error("Failed to load CSV: %s", e)
```

* Combines **error handling** with **observability** (logs ‚Üí metrics ‚Üí traces)
* Makes debugging in production easier

---

## 6Ô∏è‚É£ Step-by-Step Error Handling in PyInsight

1. **Load CSV** ‚Üí catch `FileNotFoundError`, `PermissionError`
2. **Validate Rows** ‚Üí raise `DataError` for missing/invalid data
3. **Analysis** ‚Üí catch calculation errors (`ZeroDivisionError`, `ValueError`)
4. **Report Generation** ‚Üí catch file writing errors (`IOError`)
5. **Log Everything** ‚Üí integrate with logging module for structured observability

**Flow Diagram:**

```
CSV Loader
   ‚îÇ
   ‚ñº
  Try/Except: FileNotFoundError, PermissionError
   ‚îÇ
Validation
   ‚îÇ
   ‚ñº
Custom Exception: DataError
   ‚îÇ
Analysis Engine
   ‚îÇ
   ‚ñº
Try/Except: ValueError, ZeroDivisionError
   ‚îÇ
Report Generator
   ‚îÇ
   ‚ñº
Try/Except: IOError
   ‚îÇ
Logging ‚Üí Metrics ‚Üí Traces
```

> **Takeaway:** Proper error handling in PyInsight ensures **predictable, safe, and debuggable execution**, while keeping user-friendly messages and system logs intact.

---

# üß± PHASE 4 ‚Äî Functional Programming

Functional programming in Python emphasizes **pure functions, immutability, and predictable behavior**. In PyInsight, we use these principles to make our **analytics engine testable, modular, and maintainable**.

---

## 1Ô∏è‚É£ Pure Functions

A **pure function**:

* Always produces the same output for the same input
* Has **no side effects** (does not modify global or external state)
* Is **predictable and testable**

**Example: Summarizing a Column in PyInsight**

```python
def summarize(rows, column):
    values = [float(r[column]) for r in rows]
    return {
        "count": len(values),
        "avg": sum(values) / len(values),
        "min": min(values),
        "max": max(values)
    }
```

**Benefits:**

* Easy to unit test:

```python
rows = [{"score": "10"}, {"score": "20"}, {"score": "30"}]
result = summarize(rows, "score")
assert result["avg"] == 20
assert result["count"] == 3
```

* Can be composed with other functions without worrying about hidden state
* Makes debugging simpler because output depends only on input

---

## 2Ô∏è‚É£ Immutability

Pure functions often **avoid modifying the input**. Instead of changing `rows` directly:

```python
# Avoid this (side-effect)
def normalize_in_place(rows, column):
    for r in rows:
        r[column] = float(r[column]) / 100
```

We return a **new dataset**:

```python
def normalize(rows, column):
    return [{**r, column: float(r[column])/100} for r in rows]
```

*Original data remains unchanged, preventing accidental bugs in later stages.*

---

## 3Ô∏è‚É£ Lambdas ‚Äî Anonymous Functions

Lambdas are **one-line functions** useful for short operations. In PyInsight:

```python
# Sort rows by score
rows.sort(key=lambda r: float(r["score"]))
```

**When to use:**

* Quick, short, obvious operations
* Inline with `sort`, `map`, `filter`, `reduce`

**Avoid complex logic in lambdas** ‚Äî extract to named pure functions for readability:

```python
def score_key(row):
    return float(row["score"])

rows.sort(key=score_key)
```

---

## 4Ô∏è‚É£ Higher-Order Functions

A **higher-order function** either:

* Accepts a function as an argument
* Returns a function

**Example: Apply a transformation to any column**

```python
def apply_column(rows, column, func):
    return [{**r, column: func(r[column])} for r in rows]

# Usage: convert scores to percentages
rows = apply_column(rows, "score", lambda x: float(x)/100)
```

*Encapsulates transformation logic and keeps it reusable.*

---

## 5Ô∏è‚É£ Map, Filter, Reduce

Python functional helpers allow concise transformations:

```python
from functools import reduce

# Extract scores
scores = list(map(lambda r: float(r["score"]), rows))

# Filter high scores
high_scores = list(filter(lambda x: x > 80, scores))

# Reduce to sum
total_score = reduce(lambda a, b: a+b, scores)
```

*Functional style avoids explicit loops, making intent clear.*

---

## 6Ô∏è‚É£ Benefits of Functional Programming in PyInsight

| Feature                 | Benefit                                           |
| ----------------------- | ------------------------------------------------- |
| Pure Functions          | Predictable output, easy testing                  |
| Immutability            | Prevents accidental side-effects, safer pipelines |
| Lambdas                 | Concise inline operations                         |
| Higher-Order Functions  | Reusable transformations, composable logic        |
| `map`/`filter`/`reduce` | Declarative data processing, reduces boilerplate  |

---

## 7Ô∏è‚É£ Step-by-Step Usage in PyInsight

1. **Load CSV** ‚Üí list of dicts
2. **Validate Data** ‚Üí pure function returning valid rows
3. **Analyze Columns** ‚Üí pure functions: `summarize`, `normalize`, `aggregate`
4. **Sort or Transform** ‚Üí lambdas or higher-order functions
5. **Generate Reports** ‚Üí pure formatting functions returning strings or dicts

**Text-Based Flow:**

```
CSV Loader
    ‚îÇ
    ‚ñº
Validation (pure function)
    ‚îÇ
    ‚ñº
Analysis Engine (summarize, normalize, aggregate)
    ‚îÇ
    ‚ñº
Sorting / Transformation (lambdas / map/filter)
    ‚îÇ
    ‚ñº
Report Generator (pure formatting)
```

> **Takeaway:** Functional programming keeps PyInsight **predictable, testable, and modular**, especially as datasets grow and transformations become complex.

---

# üß± PHASE 5 ‚Äî Argument Unpacking (`*args` & `**kwargs`)

In Python, argument unpacking allows functions to accept **a variable number of positional and keyword arguments**. This is a cornerstone for **flexible APIs, decorators, and modular systems**.

---

## 1Ô∏è‚É£ `*args` ‚Äî Variable Positional Arguments

`*args` allows a function to accept **any number of positional arguments** as a tuple.

```python
def log(*args):
    print("Positional arguments:", args)

log("Starting analysis", "File:", "data.csv")
```

**Output:**

```
Positional arguments: ('Starting analysis', 'File:', 'data.csv')
```

‚úÖ Use case in PyInsight: pass multiple indicators to the analysis engine without defining them upfront.

```python
def analyze(data, *indicators):
    for indicator in indicators:
        print(f"Calculating {indicator}...")
        
analyze(my_data, "RSI", "MACD", "EMA")
```

---

## 2Ô∏è‚É£ `**kwargs` ‚Äî Variable Keyword Arguments

`**kwargs` allows a function to accept **any number of named arguments** as a dictionary.

```python
def log(**kwargs):
    print("Keyword arguments:", kwargs)

log(level="INFO", module="loader", message="CSV loaded")
```

**Output:**

```
Keyword arguments: {'level': 'INFO', 'module': 'loader', 'message': 'CSV loaded'}
```

‚úÖ Use case in PyInsight: configurable options for functions or decorators.

```python
def analyze(data, **config):
    period = config.get("period", 14)
    threshold = config.get("threshold", 70)
    print(f"Using period={period}, threshold={threshold}")
    
analyze(my_data, period=20, threshold=60)
```

---

## 3Ô∏è‚É£ Combining `*args` and `**kwargs`

You can combine both to accept **any combination of positional and keyword arguments**.

```python
def analyze(data, *indicators, **config):
    print("Indicators:", indicators)
    print("Config:", config)

analyze(my_data, "RSI", "MACD", period=14, threshold=70)
```

**Output:**

```
Indicators: ('RSI', 'MACD')
Config: {'period': 14, 'threshold': 70}
```

---

## 4Ô∏è‚É£ Using Argument Unpacking When Calling Functions

You can also **unpack sequences and dictionaries** into function arguments.

```python
numbers = [1, 2, 3]
def add(a, b, c):
    return a + b + c

print(add(*numbers))  # Output: 6

params = {"a": 1, "b": 2, "c": 3}
print(add(**params))  # Output: 6
```

‚úÖ In PyInsight, this allows **passing configuration dictionaries or lists of columns** directly to functions.

---

## 5Ô∏è‚É£ Practical Benefits in PyInsight

* **Flexible APIs:** Allow users to add more indicators, metrics, or options without changing the function signature.
* **Decorators & Logging:** Wrap functions and forward any arguments without knowing them in advance.
* **Dynamic Configuration:** Pass runtime options (CLI args, config files) to core functions seamlessly.

```python
def timed(func):
    def wrapper(*args, **kwargs):
        import time
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} took {end-start:.2f}s")
        return result
    return wrapper

@timed
def summarize(rows, *columns, **options):
    print("Columns:", columns)
    print("Options:", options)
    return {col: sum(float(r[col]) for r in rows) for col in columns}

summarize(rows, "score", "age", normalize=True)
```

---

## 6Ô∏è‚É£ Summary

| Feature          | Example                          | Benefit                                    |
| ---------------- | -------------------------------- | ------------------------------------------ |
| `*args`          | `def f(*args)`                   | Accepts any number of positional arguments |
| `**kwargs`       | `def f(**kwargs)`                | Accepts any number of named arguments      |
| Unpacking        | `f(*list)`, `f(**dict)`          | Forward arguments dynamically              |
| Use in PyInsight | `analyze(*indicators, **config)` | Flexible APIs and decorators               |

---

> **Takeaway:** Mastering `*args` and `**kwargs` makes PyInsight **extensible and adaptable**, letting you write functions that can grow with future requirements without rewriting signatures.

---

# üß± PHASE 6 ‚Äî Logging & Observability

> Observability is **how you understand your system from the outside** without changing its behavior.
> It allows you to **debug, monitor, and optimize** PyInsight in production and development.

---

## 1Ô∏è‚É£ The Three Pillars of Observability

1. **Logs (Structured Events)**

   * Describe **what happened** at a point in time.
   * Include context: row IDs, filenames, timestamps.
   * Example:

```python
import logging

logging.basicConfig(
    level=logging.INFO, 
    format="%(asctime)s %(levelname)s [%(module)s] %(message)s"
)

logging.info("Loaded %d rows from %s", len(rows), filename)
logging.warning("Missing values detected in column 'score'")
logging.error("Failed to process row %d: %s", 5, row)
```

‚úÖ Tips:

* Use levels (`DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`)
* Avoid `print()` for production code
* Include structured data to help filtering and analytics

---

2. **Metrics (Quantitative Measurements)**

   * Track **how the system is performing** over time.
   * Examples in PyInsight:

* Number of rows processed per second
* Average memory usage per file
* Number of errors per dataset

- Libraries / tools: `Prometheus`, `StatsD`, `OpenTelemetry`

```python
processed_rows = len(rows)
error_count = sum(1 for r in rows if not r.get("score"))

# Pseudo-metric reporting
metrics.report("rows_processed", processed_rows)
metrics.report("errors", error_count)
```

‚úÖ Metrics give **trends and alerts**, letting you know when the system behaves abnormally.

---

3. **Traces (Flow of Execution)**

   * Show the **path of a request** through the system.
   * Useful for identifying bottlenecks, slow stages, or failed operations.
   * Example: Track how a CSV file moves through PyInsight:

```
CSV File Loaded
      ‚îÇ
      ‚ñº
Validation & Cleaning
      ‚îÇ
      ‚ñº
Analysis Engine
      ‚îÇ
      ‚ñº
Report Generation
      ‚îÇ
      ‚ñº
Logs / Metrics / Traces
```

*Tools:* `Jaeger`, `Zipkin`, `OpenTelemetry`

‚úÖ Traces help **visualize execution**, especially in multi-step pipelines or distributed systems.

---

## 2Ô∏è‚É£ Observability Implementation in PyInsight

Step-by-step:

1. **Replace `print()` with structured logging**

   ```python
   logging.info("Starting analysis for file %s", filename)
   ```
2. **Emit metrics for key operations**

   ```python
   metrics.report("rows_loaded", len(rows))
   ```
3. **Add trace markers for critical stages**

   ```python
   with tracer.span("validation"):
       validate_rows(rows)
   ```
4. **Combine logs, metrics, and traces**

   * Logs give details per event
   * Metrics give aggregate numbers
   * Traces show execution flow

---

## 3Ô∏è‚É£ Observability Flow Diagram

```
CSV Loader
      ‚îÇ
      ‚ñº
Validation
      ‚îÇ
      ‚ñº
Analysis Engine
      ‚îÇ
      ‚ñº
Report Generator
      ‚îÇ
      ‚ñº
Logs / Metrics / Traces emitted to monitoring
```

*This maps directly to PyInsight layers, ensuring every step is observable.*

---

## 4Ô∏è‚É£ Benefits for PyInsight

* Quickly pinpoint **bottlenecks or errors**
* Understand **system behavior under load**
* Debug production issues **without stopping the service**
* Provide **audit trails** and reproducibility for analytics

---

## 5Ô∏è‚É£ Step-by-Step Exercise for Readers

1. **Add structured logging** to CSV loading:

   ```python
   logging.info("Loading CSV: %s", path)
   ```
2. **Track metrics** for number of rows and missing values.
3. **Add simple traces** around `validate_rows()` and `summarize()` functions.
4. **Run the application** with a test CSV and observe logs, metrics, and traces in console output.
5. **Optionally integrate** a metrics library (`prometheus_client`) for real-time dashboards.

---

> **Takeaway:** Observability is **non-negotiable** for production-grade Python applications. In PyInsight, combining logs, metrics, and traces ensures you can **monitor, debug, and optimize** efficiently.

---


# üß± PHASE 7 ‚Äî Object-Oriented Programming (OOP)

> Object-Oriented Programming helps **manage complexity, encapsulate state, and design scalable systems**.
> In PyInsight, OOP is used to wrap CSV data, analytics logic, and reporting functionality into **modular, reusable, and testable classes**.

---

## 1Ô∏è‚É£ The Four Pillars of OOP in PyInsight

### 1. **Encapsulation**

Encapsulation hides internal state and exposes a controlled interface.

```python
class Dataset:
    def __init__(self, rows):
        self._rows = rows  # private internal state

    def summarize(self, column):
        values = [float(r[column]) for r in self._rows]
        return {"count": len(values), "avg": sum(values)/len(values)}
```

‚úÖ **Why it matters:**

* Prevents external code from accidentally modifying internal state
* Provides a single point of control to manage data
* Makes testing and debugging easier

---

### 2. **Abstraction**

Abstraction defines **what a class should do**, not how. Use **abstract base classes** for standard interfaces.

```python
from abc import ABC, abstractmethod

class Analyzer(ABC):
    @abstractmethod
    def analyze(self, data):
        """Analyze the dataset"""
        pass
```

**Example implementation:**

```python
class CSVAnalyzer(Analyzer):
    def analyze(self, data):
        print("Analyzing CSV data")
        # specific logic here
```

‚úÖ **Why it matters:**

* Sets clear contracts for subclasses
* Allows interchangeable implementations (e.g., CSV, JSON, Excel analyzers)
* Enables polymorphism

---

### 3. **Inheritance & Mixins**

Inheritance lets you **reuse and extend behavior**, while mixins add specialized functionality.

```python
class LoggingMixin:
    def log(self, message):
        print(f"[LOG] {message}")

class CSVAnalyzer(Analyzer, LoggingMixin):
    def analyze(self, data):
        self.log("Starting CSV analysis")
        # Analysis logic here
```

**Key Points:**

* `CSVAnalyzer` inherits the abstract interface from `Analyzer`
* Adds logging functionality via `LoggingMixin`
* Can extend or override methods as needed

---

### 4. **Polymorphism**

Polymorphism allows **different classes to be used interchangeably** as long as they share the same interface.

```python
def run_analysis(analyzer: Analyzer, data):
    analyzer.analyze(data)

csv_analyzer = CSVAnalyzer()
run_analysis(csv_analyzer, data)
```

*Result:* Any class implementing `Analyzer` can be passed to `run_analysis()`, enabling **flexible and extensible systems**.

---

## 2Ô∏è‚É£ Practical Example: PyInsight Dataset & Analyzer

```python
class Dataset:
    def __init__(self, rows):
        self._rows = rows

    def summarize(self, column):
        values = [float(r[column]) for r in self._rows]
        return {"count": len(values), "avg": sum(values)/len(values)}

class Analyzer(ABC):
    @abstractmethod
    def analyze(self, dataset: Dataset):
        pass

class CSVAnalyzer(Analyzer, LoggingMixin):
    def analyze(self, dataset: Dataset):
        self.log("Starting analysis")
        summary = dataset.summarize("score")
        self.log(f"Summary: {summary}")
        return summary
```

**Usage:**

```python
rows = [{"name": "Alice", "score": 85}, {"name": "Bob", "score": 90}]
dataset = Dataset(rows)
analyzer = CSVAnalyzer()
result = analyzer.analyze(dataset)
```

**Output:**

```
[LOG] Starting analysis
[LOG] Summary: {'count': 2, 'avg': 87.5}
```

---

## 3Ô∏è‚É£ Step-by-Step Guide for Readers

1. **Encapsulate Data**: Wrap CSV rows inside a `Dataset` class and hide the internal list (`_rows`).
2. **Define Abstract Interface**: Create `Analyzer` abstract base class with `analyze()` method.
3. **Implement Concrete Analyzers**: CSV, JSON, or other data sources implement `Analyzer`.
4. **Add Mixins**: Logging, timing, or metrics mixins can be reused across analyzers.
5. **Use Polymorphism**: Pass any `Analyzer` instance to generic processing functions for flexible pipelines.

---

## ‚úÖ Benefits in PyInsight

* **Modularity**: Each class has a clear responsibility
* **Extensibility**: Easily add new analyzers without changing existing code
* **Testability**: Encapsulation and abstraction simplify unit testing
* **Maintainability**: Mixins and clear contracts prevent code duplication

---

# üß± PHASE 8 ‚Äî Testing in PyInsight

> Testing is **not optional**. A system without tests is a system waiting to fail.
> PyInsight uses **unit tests, integration tests, and functional tests** to ensure reliability and safe refactoring.

---

## 1Ô∏è‚É£ Why Testing Matters

1. **Safety** ‚Äì Prevents accidental breaks when changing code.
2. **Documentation** ‚Äì Tests describe expected behavior.
3. **Refactoring Confidence** ‚Äì You can restructure code without fear of introducing bugs.
4. **Early Bug Detection** ‚Äì Catch issues before they reach production.

---

## 2Ô∏è‚É£ Types of Tests

| Type                 | Purpose                                      | Example                                        |
| -------------------- | -------------------------------------------- | ---------------------------------------------- |
| **Unit Test**        | Test a small piece of logic in isolation     | `calculate_avg()`                              |
| **Integration Test** | Test multiple components working together    | `Dataset + Analyzer`                           |
| **Functional Test**  | Test the app end-to-end                      | CLI command `pyinsight analyze data.csv score` |
| **Regression Test**  | Ensure bugs fixed in the past don‚Äôt reappear | Re-run previously failing tests                |

---

## 3Ô∏è‚É£ Unit Testing Example

```python
# pyinsight/tests/test_analysis.py
from pyinsight.analysis import calculate_avg

def test_calculate_avg():
    mock_data = [{"val": "10"}, {"val": "20"}]
    assert calculate_avg(mock_data, "val") == 15.0
```

‚úÖ **Key points:**

* Small and isolated
* Fast execution
* Focused on a **single function**
* Uses `assert` statements to check behavior

---

## 4Ô∏è‚É£ Integration Testing Example

```python
# pyinsight/tests/test_integration.py
from pyinsight.analysis import summarize
from pyinsight.loader import load_csv

def test_dataset_summary(tmp_path):
    # Create a temporary CSV file
    file = tmp_path / "data.csv"
    file.write_text("name,score\nAlice,85\nBob,90")
    
    # Load data
    rows = load_csv(file)
    
    # Summarize
    result = summarize(rows, "score")
    
    assert result["count"] == 2
    assert result["avg"] == 87.5
```

‚úÖ **Why it matters:**

* Ensures multiple modules work together correctly
* Simulates a real use case (CSV loading + analysis)

---

## 5Ô∏è‚É£ Functional / End-to-End Testing

```python
# tests/test_cli.py
from subprocess import run, PIPE

def test_cli_analysis(tmp_path):
    csv_file = tmp_path / "data.csv"
    csv_file.write_text("name,score\nAlice,85\nBob,90")
    
    result = run(["python", "pyinsight/cli.py", "--file", str(csv_file), "--column", "score"],
                 stdout=PIPE, stderr=PIPE, text=True)
    
    assert "Average: 87.5" in result.stdout
```

*Validates the **full CLI pipeline** from user input ‚Üí CSV loader ‚Üí analyzer ‚Üí output.*

---

## 6Ô∏è‚É£ Test-Driven Development (TDD) Workflow

1. **Write a failing test** for a feature you want to implement.
2. **Implement minimal code** to pass the test.
3. **Refactor code**, keeping the test passing.
4. Repeat for every feature.

‚úÖ **Benefit:** Ensures code is **always tested and modular**.

---

## 7Ô∏è‚É£ Best Practices for Testing PyInsight

* **Isolate tests** ‚Äì use temporary files or mocks instead of real data
* **Test edge cases** ‚Äì empty CSVs, missing columns, invalid data
* **Use descriptive names** ‚Äì `test_average_with_empty_list()`
* **Keep tests fast** ‚Äì use in-memory data when possible
* **Automate** ‚Äì integrate with CI/CD pipelines

---

## 8Ô∏è‚É£ Running Tests

```bash
# Run all tests
pytest

# Run a single test file
pytest tests/test_analysis.py

# Run with verbose output
pytest -v
```

‚úÖ **Tip:** Use `pytest` fixtures to create reusable mock datasets and environments.

---

## 9Ô∏è‚É£ Observability in Tests

* Use logs in tests to understand failures:

```python
import logging
logging.basicConfig(level=logging.DEBUG)

def test_debug_example():
    logging.debug("Rows: %s", [{"val": 10}])
    assert True
```

* Helps **quickly debug failing tests** without changing production code.

---

### Step-by-Step Reader Instructions:

1. **Start small:** Write unit tests for each pure function in `analysis.py`.
2. **Expand coverage:** Write integration tests combining `Dataset`, `Analyzer`, and loader modules.
3. **Test CLI:** Simulate real user input and check outputs.
4. **Automate:** Add `pytest` runs to your CI/CD pipeline.
5. **Refactor confidently:** With tests in place, you can improve code safely.

---

> **Takeaway:** Testing is the **safety net and documentation** of PyInsight. Every function, module, and CLI command should be **covered with meaningful tests**.

---

# üß± PHASE 9 ‚Äî Decorators

> Decorators allow you to **wrap functions or methods** to add behavior **without modifying their core logic**.
> They are critical for implementing cross-cutting concerns like **logging, validation, timing, caching, and authorization**.

---

## 1Ô∏è‚É£ What a Decorator Is

A **decorator** is a **function that takes another function and returns a new function** with extended behavior.

**Basic Syntax:**

```python
def my_decorator(func):
    def wrapper(*args, **kwargs):
        print("Before the function runs")
        result = func(*args, **kwargs)
        print("After the function runs")
        return result
    return wrapper

@my_decorator
def greet(name):
    print(f"Hello {name}!")

greet("Alice")
```

**Output:**

```
Before the function runs
Hello Alice!
After the function runs
```

‚úÖ Key point: `@my_decorator` is equivalent to `greet = my_decorator(greet)`.

---

## 2Ô∏è‚É£ Why Decorators Matter in PyInsight

In a **real application**, you often want to:

* Log function entry and exit
* Validate inputs
* Measure execution time
* Enforce preconditions or authorization

Without decorators, you‚Äôd have to **duplicate this logic** in every function.
Decorators **centralize cross-cutting concerns**.

---

## 3Ô∏è‚É£ Common PyInsight Decorators

### a) Timing Decorator

Tracks how long a function takes to execute:

```python
import time
import logging

def timed(func):
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        logging.info("%s executed in %.4f seconds", func.__name__, end - start)
        return result
    return wrapper
```

**Usage:**

```python
@timed
def summarize(rows, column):
    values = [float(r[column]) for r in rows]
    return {"count": len(values), "avg": sum(values)/len(values)}
```

**Result:** Every call logs its execution time automatically.

---

### b) Input Validation Decorator

Ensures functions are not called with empty or invalid data:

```python
def require_nonempty(func):
    def wrapper(rows, column, *args, **kwargs):
        if not rows:
            raise ValueError("Rows cannot be empty")
        if not column:
            raise ValueError("Column name must be provided")
        return func(rows, column, *args, **kwargs)
    return wrapper
```

**Usage:**

```python
@require_nonempty
def summarize(rows, column):
    ...
```

**Behavior:** Prevents runtime errors and centralizes input validation.

---

### c) Composing Multiple Decorators

Decorators **stack top-to-bottom**: the decorator closest to the function runs first.

```python
@timed
@require_nonempty
def summarize(rows, column):
    values = [float(r[column]) for r in rows]
    return {"count": len(values), "avg": sum(values)/len(values)}
```

**Execution Flow:**

1. `require_nonempty` checks inputs first
2. `timed` measures execution time of the actual function

**Tip:** Order matters‚Äîplace validation decorators **closest to the function**, logging or timing decorators **outermost**.

---

## 4Ô∏è‚É£ Advanced Decorator Patterns

### a) Decorators with Arguments

```python
def log_message(level="INFO"):
    def decorator(func):
        def wrapper(*args, **kwargs):
            getattr(logging, level.lower())("Running %s", func.__name__)
            return func(*args, **kwargs)
        return wrapper
    return decorator

@log_message(level="DEBUG")
def summarize(rows, column):
    ...
```

‚úÖ Provides **customizable behavior** for decorators.

---

### b) Class Method Decorators

Decorators work on methods too:

```python
class Dataset:
    def __init__(self, rows):
        self.rows = rows

    @timed
    @require_nonempty
    def summarize(self, column):
        values = [float(r[column]) for r in self.rows]
        return {"count": len(values), "avg": sum(values)/len(values)}
```

**Benefit:** Keeps your **Dataset class clean** while adding logging, timing, or validation automatically.

---

### c) Preserving Metadata with `functools.wraps`

Always use `functools.wraps` to keep function metadata:

```python
from functools import wraps

def timed(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        logging.info("%s executed in %.4f seconds", func.__name__, time.time() - start)
        return result
    return wrapper
```

**Why:** Without `wraps`, function name, docstring, and signature may be lost.

---

## 5Ô∏è‚É£ Step-by-Step Implementation in PyInsight

1. **Add decorators directory/module**

   ```
   pyinsight/
   ‚îî‚îÄ‚îÄ decorators.py
   ```

2. **Implement cross-cutting decorators**

   * `timed` for performance monitoring
   * `require_nonempty` for input validation
   * `log_message` for logging and debugging

3. **Apply decorators to core functions**

   * Analysis functions
   * CSV loader and validator
   * Report generators

4. **Verify behavior**

   * Empty rows ‚Üí raise exception
   * Execution time ‚Üí logged automatically
   * Logs formatted consistently

---

‚úÖ **Takeaway:**

Decorators allow PyInsight to be **extensible, maintainable, and production-ready** by:

* Keeping core logic clean
* Centralizing cross-cutting concerns
* Providing consistent validation, logging, and monitoring

---

# üß± PHASE üîü ‚Äî Packaging & Modules

```
pyinsight/
‚îú‚îÄ‚îÄ pyinsight/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py
‚îÇ   ‚îú‚îÄ‚îÄ decorators.py
‚îÇ   ‚îî‚îÄ‚îÄ errors.py
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ pyproject.toml
```

* Run as module: `python -m pyinsight.analysis`
---
# **NOTE**

> **üß† What Does `python -m` Mean?**

When you run:

```bash
python -m pyinsight.analysis
```

you are telling Python:

> **‚ÄúRun this module as a script, using Python‚Äôs module system.‚Äù**

This is very different from running a file directly.

---

## üîç Two Ways to Run Python Code

### ‚ùå Running a File Directly

```bash
python pyinsight/analysis.py
```

**What happens:**

* Python treats `analysis.py` as a standalone script
* The directory structure is ignored
* Imports can break
* Relative imports may fail

Example problem:

```python
# analysis.py
from pyinsight.decorators import timed
```

‚ùå This may fail if Python doesn‚Äôt know where `pyinsight` lives.

---

### ‚úÖ Running a Module (`python -m`)

```bash
python -m pyinsight.analysis
```

**What happens:**

* Python searches for `pyinsight` on `PYTHONPATH`
* Loads it as a **package**
* Executes `analysis.py` **inside its package context**
* Imports work correctly and predictably

---

## üì¶ What Is a ‚ÄúModule‚Äù vs a ‚ÄúPackage‚Äù?

| Term    | Meaning                                        |
| ------- | ---------------------------------------------- |
| Module  | A single `.py` file                            |
| Package | A directory containing modules + `__init__.py` |

Example:

```
pyinsight/          ‚Üê package
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ analysis.py    ‚Üê module
‚îú‚îÄ‚îÄ loader.py
‚îî‚îÄ‚îÄ cli.py
```

So:

```bash
python -m pyinsight.analysis
```

means:

> Run the **analysis module inside the pyinsight package**

---

## üîë Why `-m` Matters (Especially for Real Projects)

### 1Ô∏è‚É£ Correct Import Resolution

Using `-m` ensures imports work **as designed**:

```python
from pyinsight.decorators import timed
```

This works because Python knows:

```
pyinsight ‚Üí package root
analysis ‚Üí module inside package
```

---

### 2Ô∏è‚É£ Enables Relative Imports

Inside a package, you can safely use:

```python
from .decorators import timed
```

This **only works** when executed as a module.

---

### 3Ô∏è‚É£ Consistent Behavior in Development & Production

| Environment       | Works with `python -m` | Works with `python file.py` |
| ----------------- | ---------------------- | --------------------------- |
| Local dev         | ‚úÖ                      | ‚ùå sometimes                 |
| Tests             | ‚úÖ                      | ‚ùå                           |
| CI/CD             | ‚úÖ                      | ‚ùå                           |
| Installed package | ‚úÖ                      | ‚ùå                           |

---

## üîÑ What About `__name__ == "__main__"`?

When you run:

```bash
python -m pyinsight.analysis
```

Python sets:

```python
__name__ = "__main__"
```

**inside `analysis.py`**

This means:

```python
if __name__ == "__main__":
    main()
```

‚úÖ **executes normally**

But when imported:

```python
from pyinsight import analysis
```

Then:

```python
__name__ = "pyinsight.analysis"
```

‚ùå `main()` does NOT run

‚û°Ô∏è This is how Python supports **reusable modules + executable scripts**

---

## üß© How This Applies to PyInsight

### Development

```bash
python -m pyinsight.cli --file data.csv --column score
```

‚úî Correct imports
‚úî Package-aware execution
‚úî Matches production behavior

---

### Installed CLI (via `pyproject.toml`)

```bash
pyinsight --file data.csv --column score
```

Behind the scenes, Python still uses **module execution**, not file execution.

---

## üß† Mental Model (Text Diagram)

```
python -m pyinsight.analysis
        ‚îÇ
        ‚ñº
Locate package "pyinsight"
        ‚îÇ
        ‚ñº
Load module "analysis"
        ‚îÇ
        ‚ñº
Set __name__ = "__main__"
        ‚îÇ
        ‚ñº
Execute module code
```

---

## ‚úÖ When Should You Use `python -m`?

**Always use `python -m` when:**

‚úî Running code inside a package
‚úî Building reusable applications
‚úî Writing libraries or CLIs
‚úî Preparing for packaging & distribution

**Avoid running `.py` files directly** once your project has structure.

---

## üèÅ Takeaway

> `python -m` is the bridge between **scripts** and **systems**.

It ensures:

‚úî Correct imports
‚úî Predictable execution
‚úî Production-ready behavior

In short:

**Scripts use `python file.py`**
**Applications use `python -m package.module`**

---

# üß± PHASE 1Ô∏è‚É£1Ô∏è‚É£ ‚Äî CLI Tools

## From Script to Executable Interface

> A **Command-Line Interface (CLI)** is not a convenience feature.
> It is the **public API** of your application.

If the CLI is unclear, inconsistent, or unpredictable, the entire system feels fragile ‚Äî regardless of how good the internal code is.

In **PyInsight**, the CLI is the **Ingress Layer** of the system.

---

## üß† What the CLI Is Responsible For

The CLI must **never** contain business logic.
Its role is orchestration and control.

**Responsibilities:**

‚úî Capture user intent
‚úî Validate input early
‚úî Route execution to core logic
‚úî Produce deterministic output
‚úî Exit with machine-readable status codes

Everything else belongs elsewhere.

---

## üß© CLI as a System Boundary

```
User / Automation
        ‚îÇ
        ‚ñº
CLI (Ingress Layer)
        ‚îÇ
        ‚îú‚îÄ Argument parsing
        ‚îú‚îÄ Validation
        ‚îú‚îÄ Error mapping
        ‚îî‚îÄ Command routing
        ‚îÇ
        ‚ñº
Core Application Logic
```

This boundary is what allows PyInsight to scale from:

* ad-hoc scripts
* to CI pipelines
* to production batch jobs
* to packaged executables

---

## üéØ Why CLIs Matter in Real Systems

A well-designed CLI makes PyInsight:

‚úî **Automatable** ‚Äî cron, CI/CD, schedulers
‚úî **Scriptable** ‚Äî bash, PowerShell, Makefiles
‚úî **Deployable** ‚Äî containers, servers, batch nodes
‚úî **Composable** ‚Äî pipes, redirection, chaining
‚úî **Stable** ‚Äî backward-compatible interfaces

> A good CLI is usable by **humans and machines** equally well.

---

## üß† The CLI Execution Model

Every professional CLI follows the same high-level flow:

```
Command Invocation
        ‚îÇ
        ‚ñº
Argument Parsing
        ‚îÇ
        ‚ñº
Validation
        ‚îÇ
        ‚ñº
Dispatch to Core Logic
        ‚îÇ
        ‚ñº
Output + Exit Code
```

This phase teaches you how to implement that model cleanly in Python.

---

# Option 1Ô∏è‚É£ ‚Äî `argparse`

## Explicit Control, Standard Library

`argparse` is built into Python and exposes how CLIs *actually work*.

It is verbose by design ‚Äî which makes it ideal for learning and low-level control.

---

### üìÑ `pyinsight/cli.py`

```python
import argparse
from pyinsight.loader import load_csv
from pyinsight.analysis import summarize

def main():
    parser = argparse.ArgumentParser(
        description="PyInsight ‚Äî CSV Analytics Tool"
    )

    parser.add_argument(
        "--file",
        required=True,
        help="Path to CSV file"
    )

    parser.add_argument(
        "--column",
        required=True,
        help="Column to analyze"
    )

    args = parser.parse_args()

    rows = load_csv(args.file)
    result = summarize(rows, args.column)

    print(result)

if __name__ == "__main__":
    main()
```

---

### ‚ñ∂ Run as a Module

```bash
python -m pyinsight.cli --file data.csv --column score
```

Running with `-m` ensures:

* Correct import resolution
* Package-aware execution
* No reliance on relative paths

---

### ‚úÖ Concepts Introduced

* Arguments as **contracts**
* Automatic `--help` generation
* Early failure on invalid input
* Strict separation of CLI and logic

---

## When to Use `argparse`

‚úî You want zero dependencies
‚úî You need full manual control
‚úî You want to understand CLI internals

For real applications, however, verbosity becomes friction.

---

# Option 2Ô∏è‚É£ ‚Äî `typer`

## Modern, Typed, Production-Ready

`typer` builds on `click` and Python type hints to produce **clean, declarative CLIs**.

> Think of Typer as **FastAPI for the command line**.

---

### üìÑ `pyinsight/cli.py` (Typer-based)

```python
import typer
from pyinsight.loader import load_csv
from pyinsight.analysis import summarize

app = typer.Typer(
    help="PyInsight ‚Äî CSV Analytics Tool"
)

@app.command()
def analyze(
    file: str = typer.Argument(..., help="Path to CSV file"),
    column: str = typer.Argument(..., help="Column to analyze"),
):
    rows = load_csv(file)
    result = summarize(rows, column)
    typer.echo(result)

def main():
    app()

if __name__ == "__main__":
    main()
```

---

### ‚ñ∂ Run It

```bash
python -m pyinsight.cli analyze data.csv score
```

---

### üß† What Typer Gives You for Free

‚úî Type-based validation
‚úî Automatic conversion
‚úî Nested subcommands
‚úî Rich help output
‚úî Shell auto-completion
‚úî Minimal boilerplate

This dramatically reduces error surface and maintenance cost.

---

## üÜö argparse vs Typer

| Dimension        | argparse            | Typer           |
| ---------------- | ------------------- | --------------- |
| Standard library | ‚úÖ                   | ‚ùå               |
| Type awareness   | ‚ùå                   | ‚úÖ               |
| Subcommands      | Manual              | Native          |
| Readability      | Verbose             | Declarative     |
| Best use case    | Learning, low-level | Production CLIs |

**Guideline:**

* Learn with `argparse`
* Ship with `typer`

---

# üß© Scaling the CLI: Subcommands

Real tools do not expose one action ‚Äî they expose **capabilities**.

```
pyinsight analyze
pyinsight validate
pyinsight report
```

---

### üìÑ Subcommand Structure

```python
app = typer.Typer()

@app.command()
def analyze(...):
    ...

@app.command()
def validate(...):
    ...

@app.command()
def report(...):
    ...
```

This creates a **command router**, not a script.

---

## üß† Subcommands as Contracts

Each subcommand:

* Has a clear responsibility
* Can evolve independently
* Can be tested in isolation
* Is discoverable via `--help`

This is how CLIs remain stable over years.

---

# üß™ Testing the CLI (Non-Negotiable)

CLIs are **interfaces**, and interfaces must be tested.

---

### üìÑ `tests/test_cli.py`

```python
from typer.testing import CliRunner
from pyinsight.cli import app

runner = CliRunner()

def test_analyze_command():
    result = runner.invoke(app, ["analyze", "data.csv", "score"])
    assert result.exit_code == 0
```

---

### Why This Matters

‚úî Prevents breaking changes
‚úî Enables CI/CD automation
‚úî Documents expected behavior
‚úî Treats the CLI as a public API

---

# üì¶ Turning the CLI into an Executable

## Entry Point Registration

### üìÑ `pyproject.toml`

```toml
[project.scripts]
pyinsight = "pyinsight.cli:main"
```

After installation:

```bash
pyinsight analyze data.csv score
```

No `python`, no module paths ‚Äî **this is a real command**.

---

## üß† Why Entry Points Matter

They:

* Hide implementation details
* Provide stable invocation
* Enable packaging and distribution
* Are required for binaries

---

# üß† Professional Takeaway

> A CLI is an API for humans and machines.

By the end of this phase, PyInsight‚Äôs CLI:

‚úî Is explicit and predictable
‚úî Separates interface from logic
‚úî Supports automation and scripting
‚úî Scales via subcommands
‚úî Is testable and stable
‚úî Can be packaged as an executable

This is the **inflection point** where PyInsight stops being a Python script and becomes **software**.

---

### ‚úÖ Phase Outcome

Readers now know how to:

‚úî Design clean CLI boundaries
‚úî Parse and validate arguments
‚úî Implement subcommands
‚úî Test CLI behavior
‚úî Expose a real executable

---

Moving forward, we can build on this foundation to add:

‚û° Exit codes and error mapping
‚û° Shell auto-completion
‚û° Single-file binaries (PyInstaller)
‚û° Configuration and environment management

> **Syntax got you started.
> Engineering lets you ship.**

---

# üß± PHASE 1Ô∏è‚É£2Ô∏è‚É£ ‚Äî Configuration & Environment Management

> Hard-coded values do not scale.
> Configuration is how software adapts **without code changes**.

---

## üéØ Goals of This Phase

By the end of this phase, PyInsight will:

‚úî Support configuration files
‚úî Support environment variables
‚úî Have sane defaults
‚úî Be production-safe
‚úî Work identically in local, CI, and production

---

## 1Ô∏è‚É£ Configuration Strategy (Industry Standard)

We use **three layers**, evaluated in this order:

```
CLI Arguments (highest priority)
        ‚Üì
Environment Variables
        ‚Üì
Config File
        ‚Üì
Defaults (lowest priority)
```

This mirrors how tools like **Docker**, **AWS CLI**, and **Kubernetes** work.

---

## 2Ô∏è‚É£ Adding a Config File (`pyinsight.toml`)

### üìÑ Example `pyinsight.toml`

```toml
[logging]
level = "INFO"

[analysis]
default_column = "score"
precision = 2

[output]
format = "json"
```

---

## 3Ô∏è‚É£ Loading Configuration Safely

### üìÑ `pyinsight/config.py`

```python
import os
import tomllib

DEFAULT_CONFIG = {
    "logging": {"level": "INFO"},
    "analysis": {"precision": 2},
    "output": {"format": "terminal"},
}

def load_config(path: str | None = None) -> dict:
    config = DEFAULT_CONFIG.copy()

    if path and os.path.exists(path):
        with open(path, "rb") as f:
            file_config = tomllib.load(f)
            merge(config, file_config)

    return config

def merge(base: dict, override: dict):
    for k, v in override.items():
        if isinstance(v, dict):
            merge(base.setdefault(k, {}), v)
        else:
            base[k] = v
```

---

## 4Ô∏è‚É£ Environment Variable Overrides

### Example

```bash
export PYINSIGHT_LOG_LEVEL=DEBUG
```

### üìÑ `pyinsight/config.py` (extend)

```python
def apply_env_overrides(config: dict):
    if level := os.getenv("PYINSIGHT_LOG_LEVEL"):
        config["logging"]["level"] = level
```

---

## 5Ô∏è‚É£ Wiring Config Into CLI

```python
@app.callback()
def main(
    config: str = typer.Option(None, help="Path to config file"),
):
    cfg = load_config(config)
    apply_env_overrides(cfg)
```

‚úî CLI is flexible
‚úî No code changes required to reconfigure
‚úî Safe defaults always exist

---

## üß† Takeaway

> Configuration is a **contract**, not a hack.

---

# üß± PHASE 1Ô∏è‚É£3Ô∏è‚É£ ‚Äî Output Formats & UX Polishing

> Professional tools don‚Äôt just compute ‚Äî they **communicate clearly**.

---

## 1Ô∏è‚É£ Output Modes

PyInsight supports:

‚úî Terminal (human-readable)
‚úî JSON (machine-readable)
‚úî CSV (pipeline-friendly)

---

## 2Ô∏è‚É£ Output Formatter Design

### üìÑ `pyinsight/output.py`

```python
import json
import csv
import sys

def output_terminal(data: dict):
    for k, v in data.items():
        print(f"{k}: {v}")

def output_json(data: dict):
    print(json.dumps(data, indent=2))

def output_csv(data: dict):
    writer = csv.writer(sys.stdout)
    writer.writerow(data.keys())
    writer.writerow(data.values())
```

---

## 3Ô∏è‚É£ CLI Option: `--format`

```python
@app.command()
def analyze(
    file: str,
    column: str,
    format: str = typer.Option("terminal"),
):
    rows = load_csv(file)
    result = summarize(rows, column)

    match format:
        case "json":
            output_json(result)
        case "csv":
            output_csv(result)
        case _:
            output_terminal(result)
```

---

## üß† Takeaway

> CLI output is an **API surface**.

---

# üß± PHASE 1Ô∏è‚É£4Ô∏è‚É£ ‚Äî Plugin Architecture (Extensibility)

> You don‚Äôt scale systems by modifying core code.
> You scale systems by **extending them**.

---

## 1Ô∏è‚É£ Plugin Contract

```python
class Plugin:
    name: str

    def run(self, rows: list[dict]) -> dict:
        raise NotImplementedError
```

---

## 2Ô∏è‚É£ Built-In Plugin Example

```python
class AveragePlugin(Plugin):
    name = "average"

    def run(self, rows):
        values = [float(r["score"]) for r in rows]
        return {"avg": sum(values)/len(values)}
```

---

## 3Ô∏è‚É£ Plugin Loader

```python
def load_plugins():
    return {
        "average": AveragePlugin(),
    }
```

---

## 4Ô∏è‚É£ CLI Integration

```bash
pyinsight analyze data.csv --plugin average
```

---

## üß† Takeaway

> Plugin systems turn tools into **platforms**.

---

# üß± PHASE 1Ô∏è‚É£5Ô∏è‚É£ ‚Äî CI/CD (End-to-End Automation)

> If it isn‚Äôt automated, it‚Äôs broken.

---

## 1Ô∏è‚É£ CI Goals

‚úî Lint
‚úî Test
‚úî Build
‚úî Package
‚úî Fail fast

---

## 2Ô∏è‚É£ GitHub Actions Pipeline

### üìÑ `.github/workflows/ci.yml`

```yaml
name: CI

on: [push, pull_request]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: "3.12"
      - run: pip install -e .[dev]
      - run: pytest
      - run: python -m build
```

---

## 3Ô∏è‚É£ Release Automation (Optional)

```yaml
- run: pyinstaller --onefile pyinsight/cli.py
```

---

## üß† Takeaway

> CI/CD is **part of the codebase**, not infrastructure.

---

# üß± PHASE 1Ô∏è‚É£6Ô∏è‚É£ ‚Äî Distribution Strategies

You now have **three ways to ship PyInsight**:

---

### 1Ô∏è‚É£ Python Package

```bash
pip install pyinsight
```

‚úî Developers
‚úî CI systems

---

### 2Ô∏è‚É£ Single Binary (PyInstaller)

```bash
./pyinsight analyze data.csv score
```

‚úî End users
‚úî Air-gapped systems

---

### 3Ô∏è‚É£ Docker (Optional)

```dockerfile
FROM python:3.12-slim
COPY . /app
RUN pip install .
ENTRYPOINT ["pyinsight"]
```

‚úî Cloud
‚úî Kubernetes

---

# üèÅ FINAL STATE ‚Äî PyInsight Is Now Real Software

```
User
 ‚îÇ
 ‚ñº
CLI (subcommands + completion)
 ‚îÇ
 ‚ñº
Config ‚Üí Validation ‚Üí Analysis
 ‚îÇ
 ‚ñº
Logging ‚Üí Metrics ‚Üí Traces
 ‚îÇ
 ‚ñº
Output Formats
 ‚îÇ
 ‚ñº
Binary / Package / Container
```

---

# üéì What Readers Have Truly Learned

‚úî Python execution model
‚úî Data modeling
‚úî Functional & OOP design
‚úî Error handling & testing
‚úî CLI engineering
‚úî Observability
‚úî Packaging & binaries
‚úî CI/CD
‚úî Scalable architecture

> **They didn‚Äôt learn Python syntax.
> They learned Python engineering.**

---

# üß± PHASE 1Ô∏è‚É£2Ô∏è‚É£ ‚Äî Production Packaging

## From Source Code to Installable Software

> Packaging is the moment your code becomes **a product**.
>
> If your application cannot be installed, versioned, and reproduced reliably, it is not production-ready ‚Äî no matter how good the logic is.

In this phase, PyInsight becomes:

‚úî Installable
‚úî Executable
‚úî Versioned
‚úî Reproducible
‚úî Distributable

---

## üß† What ‚ÄúProduction Packaging‚Äù Really Means

Production packaging solves **non-functional requirements**:

* How do users install the tool?
* How do machines run it?
* How do versions stay consistent?
* How do dependencies stay isolated?
* How do builds remain reproducible?

This phase answers all of those questions.

---

## üß© Packaging Mental Model

```
Source Code
     ‚îÇ
     ‚ñº
pyproject.toml (Metadata + Dependencies)
     ‚îÇ
     ‚ñº
Build Backend (PEP 517 / 518)
     ‚îÇ
     ‚ñº
Wheel / Installable Package
     ‚îÇ
     ‚ñº
Executable Entry Point
```

Everything starts with **`pyproject.toml`**.

---

## üì¶ The Modern Python Packaging Standard

Python packaging today is defined by:

* **PEP 517 / 518** ‚Äî build isolation
* **PEP 621** ‚Äî project metadata in `pyproject.toml`

> `setup.py` is legacy.
> `pyproject.toml` is the future ‚Äî and the present.

---

## üìÑ `pyproject.toml` (Production-Ready)

```toml
[project]
name = "pyinsight"
version = "0.1.0"
description = "Production-grade CSV analytics CLI"
readme = "README.md"
requires-python = ">=3.9"
authors = [
  { name="PyInsight Team" }
]

dependencies = [
  "typer>=0.9",
]

[project.optional-dependencies]
dev = [
  "pytest",
  "black",
  "ruff",
]

[project.scripts]
pyinsight = "pyinsight.cli:main"
```

---

## üß† What Each Section Does

### `[project]`

Defines **who your software is**:

* `name` ‚Üí install name (`pip install pyinsight`)
* `version` ‚Üí semantic versioning
* `requires-python` ‚Üí prevents incompatible installs
* `dependencies` ‚Üí runtime requirements only

---

### Optional Dependencies

```bash
pip install .[dev]
```

Installs:

‚úî testing tools
‚úî linters
‚úî formatters

Without polluting production environments.

---

## üöÄ Installing PyInsight

From the project root:

```bash
pip install .
```

What happens:

1. Dependencies are resolved
2. Package is installed
3. Entry point is registered

---

## ‚ñ∂ Running the Installed CLI

```bash
pyinsight --help
```

```bash
pyinsight analyze data.csv score
```

There is **no reference to Python**, paths, or modules.

This is how real tools behave.

---

## üß† How Entry Points Work

```toml
[project.scripts]
pyinsight = "pyinsight.cli:main"
```

This tells Python:

```
When user types "pyinsight":
‚Üí import pyinsight.cli
‚Üí call main()
```

This mechanism works across:

‚úî macOS
‚úî Linux
‚úî Windows

---

## üìÅ Recommended Project Structure

```
pyinsight/
‚îú‚îÄ‚îÄ pyinsight/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ cli.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ validator.py
‚îÇ   ‚îú‚îÄ‚îÄ report.py
‚îÇ   ‚îî‚îÄ‚îÄ errors.py
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_analysis.py
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore
```

> Clear structure reduces cognitive load and onboarding time.

---

## üß™ Packaging Verification Checklist

Before shipping, always verify:

```bash
pip install .
pyinsight --help
pyinsight analyze data.csv score
pytest
```

If this works, your package is **deployable**.

---

## üß† Versioning Strategy (Semantic Versioning)

```
MAJOR.MINOR.PATCH
```

* `PATCH` ‚Üí bug fixes
* `MINOR` ‚Üí backward-compatible features
* `MAJOR` ‚Üí breaking changes

Example:

```
0.1.0 ‚Üí 0.1.1 ‚Üí 0.2.0 ‚Üí 1.0.0
```

This matters for CI/CD and automation consumers.

---

## üèó Why Packaging Comes *Before* CI/CD

CI/CD automates **what already works**.

If packaging is broken:

‚ùå pipelines fail
‚ùå deployments break
‚ùå environments drift

Packaging correctness is the **foundation** for everything that follows.

---

## ‚úÖ Phase Completion Outcomes

By the end of this phase, readers can:

‚úî Create modern Python packages
‚úî Define dependencies correctly
‚úî Expose real executables
‚úî Install tools with `pip`
‚úî Prepare software for distribution

PyInsight is now:

> **Installable software, not just code.**

---

## üß† Professional Takeaway

> If your project does not install cleanly, it is not finished.

With production packaging in place, PyInsight is ready for:

‚û° CI/CD pipelines
‚û° Binary packaging (PyInstaller)
‚û° Docker images
‚û° Enterprise deployment

---

# üß± PHASE 1Ô∏è‚É£3Ô∏è‚É£ ‚Äî CI/CD

## From Local Code to Reproducible Releases

> CI/CD is not about automation.
> It is about **trust**.
>
> Trust that every change is tested, every artifact is reproducible, and every release is intentional.

In this phase, PyInsight gains:

‚úî Automated testing
‚úî Consistent formatting and linting
‚úî Deterministic builds
‚úî Repeatable releases
‚úî Machine-verifiable quality gates

---

## üß† What CI/CD Solves in Real Systems

Without CI/CD:

* Bugs slip into production
* ‚ÄúWorks on my machine‚Äù becomes the norm
* Releases are manual, risky, and slow
* Confidence erodes with every change

With CI/CD:

* Every commit is validated
* Failures are caught early
* Releases are predictable
* Engineers refactor safely

---

## üß© CI/CD Mental Model

```
Code Commit
     ‚îÇ
     ‚ñº
Continuous Integration (CI)
     ‚îÇ
     ‚îú‚îÄ‚îÄ Install dependencies
     ‚îú‚îÄ‚îÄ Lint & format
     ‚îú‚îÄ‚îÄ Run tests
     ‚îî‚îÄ‚îÄ Build artifacts
     ‚îÇ
     ‚ñº
Continuous Delivery / Deployment (CD)
     ‚îÇ
     ‚îú‚îÄ‚îÄ Version tagging
     ‚îú‚îÄ‚îÄ Publish package
     ‚îî‚îÄ‚îÄ Ship binaries
```

CI answers: **‚ÄúIs this change safe?‚Äù**
CD answers: **‚ÄúCan this change be released?‚Äù**

---

## üîß Tooling Choices for PyInsight

| Concern      | Tool           | Reason                     |
| ------------ | -------------- | -------------------------- |
| CI Platform  | GitHub Actions | Ubiquitous, free, reliable |
| Test Runner  | pytest         | Fast, expressive           |
| Linting      | ruff           | Extremely fast, modern     |
| Formatting   | black          | Deterministic              |
| Build System | build          | PEP 517 compliant          |
| Packaging    | pyproject.toml | Modern standard            |

---

## üìÑ GitHub Actions Workflow

### `.github/workflows/ci.yml`

```yaml
name: CI

on:
  push:
  pull_request:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install .[dev] build

      - name: Lint
        run: ruff pyinsight

      - name: Format check
        run: black --check pyinsight

      - name: Run tests
        run: pytest

      - name: Build package
        run: python -m build
```

---

## üß† What Each Step Guarantees

### 1Ô∏è‚É£ Checkout

Ensures the workflow runs against **exact commit state**.

---

### 2Ô∏è‚É£ Python Setup

Locks runtime consistency:

‚úî Same interpreter
‚úî Same behavior
‚úî Same results

---

### 3Ô∏è‚É£ Dependency Installation

```bash
pip install .[dev] build
```

Ensures:

* Runtime deps are installable
* Dev tools work
* `pyproject.toml` is correct

---

### 4Ô∏è‚É£ Linting (`ruff`)

Prevents:

‚ùå unused imports
‚ùå shadowed variables
‚ùå subtle bugs

Fast enough to run on every commit.

---

### 5Ô∏è‚É£ Formatting (`black`)

Enforces:

‚úî consistent style
‚úî zero bike-shedding
‚úî clean diffs

---

### 6Ô∏è‚É£ Tests (`pytest`)

Tests are the **non-negotiable gate**.

If tests fail:

```
‚ùå pipeline fails
‚ùå merge blocked
```

---

### 7Ô∏è‚É£ Build Artifact

```bash
python -m build
```

Validates:

‚úî package metadata
‚úî dependency resolution
‚úî installability

Build failures are **release blockers**.

---

## üö¶ CI as a Quality Gate

A merge is allowed only if:

‚úî Lint passes
‚úî Format is correct
‚úî Tests pass
‚úî Build succeeds

This creates **engineering discipline**.

---

## üì¶ Preparing for Continuous Delivery

Once CI is stable, CD becomes trivial.

### Example: Tag-Based Release

```
git tag v0.1.0
git push origin v0.1.0
```

CI can detect the tag and:

‚úî build artifacts
‚úî publish to PyPI
‚úî attach binaries

---

## üîê Secrets & Security

Sensitive data (tokens, credentials):

* Stored in GitHub Secrets
* Never committed
* Injected at runtime

This is **non-negotiable** for production.

---

## üß™ CI Testing Philosophy

| Test Type   | Runs In CI | Purpose             |
| ----------- | ---------- | ------------------- |
| Unit        | ‚úÖ Always   | Protect behavior    |
| Integration | ‚ö† Optional | Validate boundaries |
| E2E         | ‚ùå Rare     | Slow, brittle       |

Fast CI is **a competitive advantage**.

---

## üß† Professional Takeaway

> CI/CD is the enforcement mechanism for engineering standards.

Without CI/CD:

* Standards are suggestions

With CI/CD:

* Standards are law

---

## ‚úÖ Phase Completion Outcomes

By the end of this phase, readers can:

‚úî Build CI pipelines from scratch
‚úî Enforce quality gates
‚úî Detect regressions automatically
‚úî Produce reproducible artifacts
‚úî Prepare projects for automated release

PyInsight now has **institutional memory** encoded in automation.

---

# üß± PHASE 1Ô∏è‚É£4Ô∏è‚É£ ‚Äî Observability

> Observability is **how you understand your system from the outside**, without changing its behavior.
> It ensures you can **monitor, debug, and optimize** production systems effectively.

---

## 1Ô∏è‚É£ The Three Pillars of Observability

Observability in Python (and in PyInsight) relies on **three key pillars**:

### 1. Logs ‚Äî Record What Happened

* **Definition:** Structured events describing **what happened, when, and where** in your system.
* **Purpose:** Quickly identify issues and understand flow.
* **Implementation Example:**

```python
import logging

# Configure structured logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)

logging.info("Loaded %d rows from file %s", len(rows), filename)
logging.warning("Missing values in column 'score'")
logging.error("Failed to process row %d: %s", 5, row)
```

**Tips:**

* Use **levels**: `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`
* Include **context**: row numbers, filenames, function names
* Avoid `print()` in production

---

### 2. Metrics ‚Äî Quantitative Measurements

* **Definition:** Numbers that quantify your system‚Äôs performance over time.
* **Purpose:** Monitor health, track trends, detect anomalies.
* **Examples in PyInsight:**

  * Rows processed per second
  * Memory usage while loading large CSVs
  * Error count per file
* **Implementation Example (Prometheus client for Python):**

```python
from prometheus_client import Counter, start_http_server

# Start Prometheus metrics server
start_http_server(8000)

# Define metric
rows_processed = Counter("rows_processed_total", "Number of rows processed")

# Increment during processing
for row in rows:
    rows_processed.inc()
```

**Tip:** Metrics are often **scraped** by monitoring systems like Prometheus, Grafana, or StatsD.

---

### 3. Traces ‚Äî Follow the Flow

* **Definition:** Track the execution path of requests or operations across components.
* **Purpose:** Understand **latency, bottlenecks, and dependencies**.
* **PyInsight Example:** Track a CSV file through Loader ‚Üí Validator ‚Üí Analysis ‚Üí Report Generator.
* **Implementation Example (OpenTelemetry):**

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, SimpleSpanProcessor

trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)
trace.get_tracer_provider().add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))

with tracer.start_as_current_span("load_csv"):
    rows = load_csv("data.csv")

with tracer.start_as_current_span("analyze_data"):
    analysis = summarize(rows, "score")
```

**Tip:** Traces help **pinpoint performance bottlenecks** and **understand dependencies**.

---

## 2Ô∏è‚É£ Observability Flow in PyInsight

**Step-by-step visual flow** of how logs, metrics, and traces interact in PyInsight:

```
CSV File Loaded
      ‚îÇ
      ‚ñº
Validation & Cleaning
      ‚îÇ
      ‚ñº
Analysis Engine
      ‚îÇ
      ‚ñº
Report Generation
      ‚îÇ
      ‚ñº
Logs, Metrics, Traces
```

**Key Observability Benefits:**

1. **Debug faster** ‚Äì Find errors without guessing
2. **Monitor performance** ‚Äì Detect slow processes or memory spikes
3. **Optimize workflow** ‚Äì Identify bottlenecks in the analysis engine
4. **Ensure reliability** ‚Äì Catch and fix issues before they reach users

---

## 3Ô∏è‚É£ Practical Step-by-Step Instructions

**Step 1:** Add logging to each module

* Loader: Log CSV read start, row count, missing values
* Validator: Log invalid rows, skipped rows
* Analyzer: Log functions called, metrics computed
* Reporter: Log report generation success or failure

**Step 2:** Collect metrics

* Define counters, timers, and gauges for critical operations
* Expose them via HTTP endpoint for monitoring

**Step 3:** Trace execution

* Wrap each major phase (Loader, Validator, Analyzer, Reporter) in a **trace span**
* Use this for debugging latency or performance issues

**Step 4:** Visualize and act

* Use dashboards (Grafana, Kibana) to monitor logs, metrics, and traces in real time
* Use alerts for failures, slow performance, or anomalies

---

‚úÖ **Takeaway:** Observability is **not optional**‚Äîit transforms a script into a **maintainable, production-ready system**. Every module in PyInsight should log its activity, expose metrics, and participate in traces.

---

# üß± PHASE 1Ô∏è‚É£5Ô∏è‚É£ ‚Äî Large-Scale Python Systems

**Scales Well:**

* Pure functions, clear contracts, explicit boundaries, testing

**Does Not Scale:**

* Global variables, hidden mutable state, magic

**System Mental Model:**

```
User Input
   ‚îÇ
CSV Loader ‚Üí Validator ‚Üí Analysis ‚Üí Reports
   ‚îÇ
   ‚îî‚îÄ‚îÄ Logs / Metrics / Traces
```

> **Takeaway:** Design for clarity, modularity, observability from day one.

---

‚úÖ **Next Step for Readers:**

* Implement each phase **step by step** in `pyinsight/`
* Use `pytest` to test each component
* Package using `pyproject.toml`
* Run as CLI tool locally
* Integrate CI/CD to ensure production readiness

---

# üìÇ Appendix ‚Äî PyInsight Production Ready Source Code & Architecture

> Complete, production-grade PyInsight project, including CLI, async pipelines, plugins, metrics, secrets, Docker/Kubernetes, and rule engines.

---

## üìÅ Project Directory Structure

```
pyinsight/
‚îú‚îÄ‚îÄ pyinsight/                   # Core package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ cli.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py
‚îÇ   ‚îú‚îÄ‚îÄ loader_async.py          # Async CSV loader
‚îÇ   ‚îú‚îÄ‚îÄ validator.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis_async.py        # Async analysis
‚îÇ   ‚îú‚îÄ‚îÄ reports.py
‚îÇ   ‚îú‚îÄ‚îÄ decorators.py
‚îÇ   ‚îú‚îÄ‚îÄ errors.py
‚îÇ   ‚îú‚îÄ‚îÄ logger.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ secrets.py
‚îÇ   ‚îî‚îÄ‚îÄ plugins/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ base.py
‚îú‚îÄ‚îÄ pyinsight_plugins/           # User/company-specific plugins
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ rsi.py
‚îú‚îÄ‚îÄ tests/                       # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ test_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ test_loader.py
‚îÇ   ‚îî‚îÄ‚îÄ test_validator.py
‚îú‚îÄ‚îÄ data/                        # Sample datasets
‚îÇ   ‚îî‚îÄ‚îÄ data.csv
‚îú‚îÄ‚îÄ pyproject.toml               # Packaging and dependencies
‚îú‚îÄ‚îÄ pyinsight.toml               # Runtime config
‚îú‚îÄ‚îÄ rules.yaml                   # Rule engine definitions
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ k8s-job.yaml                 # Kubernetes batch job
```

---

## 1Ô∏è‚É£ Core Package: `pyinsight/`

### `__init__.py`

```python
"""
PyInsight ‚Äî Production-Grade CSV Analysis CLI
"""
__version__ = "0.1.0"
```

### `errors.py`

```python
class PyInsightError(Exception):
    exit_code = 1

class DataError(PyInsightError):
    exit_code = 2

class ValidationError(PyInsightError):
    exit_code = 3
```

### `logger.py`

```python
import logging

def configure_logging(level=logging.INFO):
    logging.basicConfig(
        level=level,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    )

logger = logging.getLogger("pyinsight")
```

### `decorators.py`

```python
import time
from functools import wraps
from pyinsight.logger import logger
from pyinsight.errors import ValidationError

def timed(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - start
        logger.info("Function %s executed in %.4fs", func.__name__, elapsed)
        return result
    return wrapper

def require_nonempty(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        if not args or not args[0]:
            raise ValidationError(f"{func.__name__} received empty input")
        return func(*args, **kwargs)
    return wrapper
```

---

### `loader.py` ‚Äî Synchronous CSV

```python
import csv
from pyinsight.errors import DataError
from pyinsight.logger import logger

def load_csv(path: str) -> list[dict]:
    try:
        with open(path, newline="", encoding="utf-8") as f:
            rows = list(csv.DictReader(f))
            logger.info("Loaded %d rows from %s", len(rows), path)
            return rows
    except FileNotFoundError:
        raise DataError(f"File not found: {path}")
    except Exception as exc:
        raise DataError(str(exc))
```

### `loader_async.py` ‚Äî Async CSV

```python
import aiofiles, csv

async def load_csv_async(path: str) -> list[dict]:
    async with aiofiles.open(path, "r", encoding="utf-8") as f:
        content = await f.read()
        return list(csv.DictReader(content.splitlines()))
```

---

### `validator.py`

```python
from pyinsight.errors import ValidationError

def validate_rows(rows: list[dict], required_columns: list[str]) -> None:
    for idx, row in enumerate(rows, start=1):
        for col in required_columns:
            if col not in row or row[col] == "":
                raise ValidationError(f"Missing or empty '{col}' in row {idx}")
```

---

### `analysis.py`

```python
from pyinsight.decorators import timed, require_nonempty
from pyinsight.logger import logger

@timed
@require_nonempty
def summarize(rows: list[dict], column: str) -> dict:
    values = [float(r[column]) for r in rows if r[column] != ""]
    count = len(values)
    result = {
        "count": count,
        "avg": sum(values)/count if count else 0,
        "min": min(values) if values else 0,
        "max": max(values) if values else 0
    }
    logger.info("Summary for column '%s': %s", column, result)
    return result
```

### `analysis_async.py`

```python
import asyncio
from pyinsight.loader_async import load_csv_async
from pyinsight.analysis import summarize

async def analyze_async(path: str, column: str):
    rows = await load_csv_async(path)
    return summarize(rows, column)
```

---

### `reports.py`

```python
import json
from pyinsight.logger import logger

def report_terminal(summary: dict, column: str):
    print(f"\nSummary for column: {column}")
    print("-"*30)
    for k,v in summary.items():
        print(f"{k:<10}: {v}")

def report_json(summary: dict, column: str, path: str):
    with open(path, "w", encoding="utf-8") as f:
        json.dump({column: summary}, f, indent=2)
    logger.info("Report written to %s", path)
```

---

### `config.py`

```python
import tomllib
from pathlib import Path

def load_config(path: str | None):
    if not path: return {}
    p = Path(path)
    if not p.exists(): raise FileNotFoundError(f"Config not found: {path}")
    with p.open("rb") as f:
        return tomllib.load(f)
```

---

### `metrics.py`

```python
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider

metrics.set_meter_provider(MeterProvider())
meter = metrics.get_meter("pyinsight")
rows_processed = meter.create_counter("rows_processed", unit="rows")
```

---

### `secrets.py`

```python
import os

def get_secret(name: str, default=None):
    value = os.getenv(name, default)
    if value is None:
        raise RuntimeError(f"Missing secret: {name}")
    return value
```

---

### `plugins/base.py`

```python
from abc import ABC, abstractmethod

class Plugin(ABC):
    name: str
    @abstractmethod
    def analyze(self, rows: list[dict]) -> dict:
        ...
```

---

### `cli.py`

```python
import typer, asyncio
from pyinsight.loader import load_csv
from pyinsight.analysis import summarize
from pyinsight.validator import validate_rows
from pyinsight.reports import report_terminal, report_json
from pyinsight.errors import PyInsightError
from pyinsight.analysis_async import analyze_async
from pyinsight.logger import configure_logging

app = typer.Typer(help="PyInsight ‚Äî CSV Analysis Tool")

@app.command()
def analyze(file: str, column: str, json_out: str | None = None):
    rows = load_csv(file)
    validate_rows(rows, [column])
    summary = summarize(rows, column)
    report_terminal(summary, column)
    if json_out: report_json(summary, column, json_out)

@app.command()
def analyze_async_cli(file: str, column: str):
    summary = asyncio.run(analyze_async(file, column))
    report_terminal(summary, column)

def main():
    configure_logging()
    try:
        app()
    except PyInsightError as e:
        typer.echo(f"Error: {e}", err=True)
        raise typer.Exit(code=e.exit_code)

if __name__=="__main__":
    main()
```

---

## 2Ô∏è‚É£ Plugin Example: `pyinsight_plugins/rsi.py`

```python
from pyinsight.plugins.base import Plugin

class RSICalculator(Plugin):
    name = "rsi"
    def analyze(self, rows):
        return {"rsi": 42}  # Placeholder for actual calculation
```

---

## 3Ô∏è‚É£ Test Example: `tests/test_analysis.py`

```python
from pyinsight.analysis import summarize

def test_summarize_basic():
    rows = [{"score": "10"}, {"score": "20"}, {"score": "30"}]
    result = summarize(rows, "score")
    assert result["count"] == 3
    assert result["avg"] == 20
    assert result["min"] == 10
    assert result["max"] == 30
```

---

## 4Ô∏è‚É£ Sample CSV: `data/data.csv`

```csv
name,score
Alice,95
Bob,82
Charlie,67
Diana,40
```

---

## 5Ô∏è‚É£ Configuration: `pyinsight.toml`

```toml
[logging]
level = "INFO"

[data]
delimiter = ","
encoding = "utf-8"

[analysis]
default_column = "score"

[report]
format = "json"
output = "report.json"
```

---

## 6Ô∏è‚É£ Rule Engine: `rules.yaml`

```yaml
rules:
  - name: high_score
    column: score
    condition: "value > 90"
    action: "flag"
  - name: low_score
    column: score
    condition: "value < 40"
    action: "warn"
```

---

## 7Ô∏è‚É£ Dockerfile

```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY pyproject.toml .
RUN pip install .
COPY pyinsight pyinsight
ENTRYPOINT ["pyinsight"]
```

---

## 8Ô∏è‚É£ Kubernetes Job: `k8s-job.yaml`

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pyinsight-job
spec:
  template:
    spec:
      containers:
        - name: pyinsight
          image: pyinsight:latest
          args: ["analyze", "/data/data.csv", "score"]
      restartPolicy: Never
```

---

## 9Ô∏è‚É£ Pyproject.toml

```toml
[project]
name = "pyinsight"
version = "0.1.0"
description = "Production-grade CSV analysis CLI"
dependencies = ["typer", "opentelemetry-api", "opentelemetry-sdk"]

[project.optional-dependencies]
dev = ["pytest", "ruff", "black", "build"]

[project.scripts]
pyinsight = "pyinsight.cli:main"
```

---

# üèó Architecture Overview & Data Flow

```
CLI / Typer
   ‚îÇ
   ‚ñº
Config Loader
   ‚îÇ
   ‚ñº
Command Router / Orchestrator
   ‚îÇ
   ‚îú‚îÄ Core Engine (loader, validator, analysis, reports)
   ‚îú‚îÄ Async Pipeline (loader_async, analysis_async)
   ‚îú‚îÄ Rule Engine (rules.yaml)
   ‚îî‚îÄ Plugin Orchestrator (pyinsight_plugins/*)
       ‚îÇ
       ‚ñº
Aggregator / Result Merge
   ‚îÇ
   ‚ñº
Output Layer (Terminal, JSON, CSV)
   ‚îÇ
   ‚ñº
Observability (metrics, logs, traces)
   ‚îÇ
   ‚ñº
Secrets / Config Management
   ‚îÇ
   ‚ñº
Deployment (Docker / Kubernetes)
```

---

# üïí Async + Plugins + Rules Execution Timeline

```
Task         0ms       100ms       200ms       300ms       400ms       500ms
----------------------------------------------------------------------------
CSV Load     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Validation           ‚ñà‚ñà‚ñà‚ñà‚ñà
Async Load              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Async Summarize                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Rule Eval      ‚ñà‚ñà‚ñà‚ñà
Plugin RSI                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Plugin Volatility                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Aggregation                               ‚ñà‚ñà‚ñà
Output Layer                                     ‚ñà
```

* **Async pipelines** run in parallel with plugins.
* **Aggregator merges results** after all async and plugin tasks finish.
* Observability metrics/logs are captured throughout.
* Secrets are injected dynamically where required.
